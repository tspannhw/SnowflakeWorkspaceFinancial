import streamlit as st
from snowflake.snowpark.context import get_active_session
import snowflake.snowpark.functions as F
import pandas as pd
import numpy as np
import json
from datetime import datetime, timedelta

# Configure Streamlit page
st.set_page_config(
    page_title="Financial Services AI Demo",
    page_icon="üè¶",
    layout="wide"
)

# Main title and description
st.title("üè¶ Financial Services Asset Management AI Demo")
st.markdown("""
### Powered by Snowflake AISQL Functions
This demo showcases intelligent financial data analysis using:
- **AI_COMPLETE**: Generate trading insights and summaries
- **AI_CLASSIFY**: Multi-label categorization with detailed descriptions and examples  
- **AI_FILTER**: Intelligent filtering with natural language, including advanced JOIN operations to correlate news with trades
- **AI_SUMMARIZE_AGG**: Aggregate and summarize news headlines to extract market themes
- **AI_SENTIMENT**: Multi-dimensional sentiment analysis of news headlines across financial aspects
- **AI_PARSE_DOCUMENT**: Parse and analyze financial documents with layout awareness
- **AI_EXTRACT**: Extract specific financial data from documents using natural language queries

**Dataset includes:** Portfolio Managers, Traders, Trades, Stock History, Market News Headlines, and Financial Documents
""")

# Get the current session
session = get_active_session()

# Removed format_info_with_sql function - now using collapsible expanders for SQL queries

# Helper function to get filtered/sampled data for AI analysis with better diversity
def get_sample_data_sql(limit=1000, date_filter="All Available Data", additional_where=""):
    """Generate SQL for sampling large dataset efficiently with diversity across traders, stocks, and trade sizes"""
    
    # Date filter conditions based on the actual max date in the dataset
    date_conditions = {
        "Most Recent 30 Days": """AND "DATE" >= (
            SELECT DATEADD(day, -30, MAX("DATE")) FROM FINSERVAM_DEMO.AISQL_DEMO.TRADE
        )""",
        "Most Recent 90 Days": """AND "DATE" >= (
            SELECT DATEADD(day, -90, MAX("DATE")) FROM FINSERVAM_DEMO.AISQL_DEMO.TRADE
        )""",
        "Most Recent Year": """AND "DATE" >= (
            SELECT DATEADD(year, -1, MAX("DATE")) FROM FINSERVAM_DEMO.AISQL_DEMO.TRADE
        )""",
        "All Available Data": ""
    }
    
    date_clause = date_conditions.get(date_filter, "")
    where_clause = f"WHERE 1=1 {date_clause} {additional_where}" if date_clause or additional_where else ""
    
    # Simplified but effective sampling strategy
    return f"""
    SELECT * FROM FINSERVAM_DEMO.AISQL_DEMO.TRADE 
    {where_clause}
    ORDER BY RANDOM()
    LIMIT {limit}
    """

# Sidebar for navigation
st.sidebar.title("üß≠ Navigation")
analysis_type = st.sidebar.radio(
    "Choose Analysis Type:",
    ["üìä Basic Analytics", "ü§ñ AI-Powered Insights", "üîç Intelligent Filtering", "üìà Market Sentiment", "üìÑ Document Analysis", "üí¨ Natural Language Queries"]
)

# Sampling controls for large dataset
st.sidebar.markdown("---")
st.sidebar.markdown("### ‚öôÔ∏è Data Sampling")

sample_size = st.sidebar.selectbox(
    "AI Analysis Sample Size:",
    [100, 500, 1000, 5000, 10000],
    index=2,  # Default to 1000
    help="Number of rows to analyze with AI functions"
)

date_filter = st.sidebar.selectbox(
    "Data Range:",
    ["Most Recent 30 Days", "Most Recent 90 Days", "Most Recent Year", "All Available Data"],
    index=3,  # Default to all data since it's demo data
    help="Filter based on the most recent data in the dataset (not current date)"
)

# Note: SQL queries are now shown inline with each AI function execution

# Get Snowpark DataFrames (stay in Snowflake - no data movement)
try:
    df_trader = session.table("FINSERVAM_DEMO.AISQL_DEMO.TRADER")
    df_trades = session.table("FINSERVAM_DEMO.AISQL_DEMO.TRADE") 
    df_position = session.table("FINSERVAM_DEMO.AISQL_DEMO.POSITION_NOW")
    
    # Test connection by getting row counts
    trader_count = df_trader.count()
    trades_count = df_trades.count()
    
    st.sidebar.info(f"üìä {trader_count:,} traders, {trades_count:,} trades")
    
    # Show actual date range in the dataset
    try:
        date_range_query = """
        SELECT 
            MIN("DATE") as earliest_date,
            MAX("DATE") as latest_date,
            DATEDIFF(day, MIN("DATE"), MAX("DATE")) as total_days
        FROM FINSERVAM_DEMO.AISQL_DEMO.TRADE
        """
        date_info = session.sql(date_range_query).to_pandas().iloc[0]
        st.sidebar.info(f"üìÖ Data: {date_info['EARLIEST_DATE']} to {date_info['LATEST_DATE']} ({date_info['TOTAL_DAYS']} days)")
    except Exception as e:
        st.sidebar.warning("üìÖ Could not determine date range")
    
    # Show table structure for debugging
    if st.sidebar.button("üîç Show Table Structure"):
        st.sidebar.write("**TRADE Table Columns:**")
        try:
            sample_row = df_trades.limit(1).to_pandas()
            for col in sample_row.columns:
                st.sidebar.write(f"- {col}")
        except Exception as e:
            st.sidebar.error(f"Error: {e}")
    
except Exception as e:
    st.error(f"‚ùå Error connecting to Snowflake tables: {e}")
    st.stop()

# Debug section - show available data
if st.sidebar.button("üîç Show Available Traders"):
    st.sidebar.write("**All Traders:**")
    try:
        all_traders = df_trader.select("TRADER", "PM").distinct().collect()
        for trader_row in all_traders:
            st.sidebar.write(f"- {trader_row['TRADER']} (PM: {trader_row['PM']})")
    except Exception as e:
        st.sidebar.error(f"Error: {e}")

# =================== BASIC ANALYTICS ===================
if analysis_type == "üìä Basic Analytics":
    st.header("üìä Basic Financial Analytics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üéØ Trader Selection")

        # Get unique PMs using Snowpark (stays in Snowflake)
        pm_list = df_trader.select("PM").distinct().collect()
        pm_options = [row['PM'] for row in pm_list]
        
        # Set the default PM to 'Kim Stephens'
        default_pm_index = 0
        if 'Kim Stephens' in pm_options:
            default_pm_index = pm_options.index('Kim Stephens')
        
        portfolio_manager = st.selectbox("Portfolio Manager:", pm_options, index=default_pm_index)
         
        # Get traders for selected PM
        trader_list = df_trader.filter(F.col("PM") == portfolio_manager).select("TRADER").distinct().collect()
        trader_options = [row['TRADER'] for row in trader_list]
        
        # Set the default trader to 'Jesse Henry' or first available
        default_trader_index = 0
        if 'Jesse Henry' in trader_options:
            default_trader_index = trader_options.index('Jesse Henry')
        elif len(trader_options) > 0:
            # If Jesse Henry not found, use the first trader
            default_trader_index = 0
        
        trader = st.selectbox("Trader:", trader_options, index=default_trader_index)
        
        # Get buying power for selected trader with error handling
        try:
            buying_power_result = df_trader.filter(F.col("TRADER") == trader).select("BUYING_POWER").collect()
            if buying_power_result and len(buying_power_result) > 0:
                buying_power = buying_power_result[0]['BUYING_POWER']
                if buying_power is not None:
                    st.metric("üí∞ Buying Power", f"${buying_power:,.2f}")
                else:
                    st.metric("üí∞ Buying Power", "N/A")
            else:
                st.metric("üí∞ Buying Power", "No data")
        except Exception as e:
            st.error(f"Error getting buying power: {e}")
            st.metric("üí∞ Buying Power", "Error")
    
    with col2:
        st.subheader("üìà Quick Stats")
        
        # Get trade statistics using Snowpark aggregations
        trader_trades_df = df_trades.filter(F.col("TRADER") == trader)
        
        # Calculate stats in Snowflake
        stats = trader_trades_df.agg([
            F.count("*").alias("total_trades"),
            F.count_distinct(F.col("SYMBOL")).alias("unique_stocks"), 
            F.avg(F.col("NUM_SHARES")).alias("avg_quantity")
        ]).collect()[0]
        
        col2a, col2b, col2c = st.columns(3)
        with col2a:
            st.metric("üîÑ Total Trades", stats['TOTAL_TRADES'] or 0)
        with col2b:
            st.metric("üìä Unique Stocks", stats['UNIQUE_STOCKS'] or 0)
        with col2c:
            # Handle None values for average quantity
            avg_qty = stats['AVG_QUANTITY']
            if avg_qty is not None:
                st.metric("üìè Avg Quantity", f"{avg_qty:.0f}")
            else:
                st.metric("üìè Avg Quantity", "N/A")
    
    # Display trader's trades (only convert to pandas for display)
    st.subheader(f"üìã Trades by {trader}")
    try:
        trader_trades_display = trader_trades_df.to_pandas()
        if len(trader_trades_display) > 0:
            st.dataframe(trader_trades_display, use_container_width=True)
        else:
            st.info(f"No trades found for trader: {trader}")
    except Exception as e:
        st.error(f"Error displaying trades: {e}")
    
    # Large quantity filter
    st.subheader("üîç Large Quantity Filter")
    col3, col4 = st.columns(2)
    with col3:
        quantity_threshold = st.number_input("Minimum Quantity Threshold:", min_value=1, value=1000)
    with col4:
        # Get stock list efficiently
        stock_list = df_trades.select(F.col("SYMBOL")).distinct().collect()
        stock_options = ['ALL'] + [row["SYMBOL"] for row in stock_list]
        selected_stock = st.selectbox("Stock Symbol:", stock_options)
    
    # Filter large trades using Snowpark
    large_trades_df = df_trades.filter(F.col("NUM_SHARES") >= quantity_threshold)
    if selected_stock != 'ALL':
        large_trades_df = large_trades_df.filter(F.col("SYMBOL") == selected_stock)
    
    # Get count and display
    large_trades_count = large_trades_df.count()
    st.write(f"**Found {large_trades_count} trades with quantity >= {quantity_threshold}**")
    
    if large_trades_count > 0:
        # Only convert to pandas for display, limit to reasonable number
        large_trades_display = large_trades_df.limit(1000).to_pandas()
        st.dataframe(large_trades_display, use_container_width=True)

# =================== AI-POWERED INSIGHTS ===================
elif analysis_type == "ü§ñ AI-Powered Insights":
    st.header("ü§ñ AI-Powered Trading Insights")
    
    # AI_COMPLETE for trading insights
    st.subheader("üí° AI Trading Analysis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Get trader list using Snowpark
        trader_list = df_trader.select("TRADER").distinct().collect()
        trader_options = [row['TRADER'] for row in trader_list]
        
        # Set default to Jesse Henry
        default_trader_index = 0
        if 'Jesse Henry' in trader_options:
            default_trader_index = trader_options.index('Jesse Henry')
        
        selected_trader = st.selectbox("Select Trader for Analysis:", trader_options, index=default_trader_index)
    
    with col2:
        analysis_period = st.selectbox("Analysis Period:", ["All Time", "Last 7 Days", "Last 30 Days"])
    
    if st.button("üîç Generate AI Insights"):
        with st.spinner("ü§ñ Generating AI insights..."):
            try:
                # Use SQL directly to avoid Snowpark column name issues
                trader_stats_query = f"""
                WITH trader_data AS (
                    SELECT * FROM FINSERVAM_DEMO.AISQL_DEMO.TRADE 
                    WHERE "TRADER" = '{selected_trader}'
                ),
                stats AS (
                    SELECT 
                        COUNT(*) as total_trades,
                        COUNT(DISTINCT "SYMBOL") as unique_stocks,
                        AVG("NUM_SHARES") as avg_quantity,
                        SUM("NUM_SHARES") as total_volume
                    FROM trader_data
                ),
                top_stock AS (
                    SELECT "SYMBOL" as most_traded_stock
                    FROM trader_data
                    GROUP BY "SYMBOL"
                    ORDER BY COUNT(*) DESC
                    LIMIT 1
                )
                SELECT 
                    s.total_trades,
                    s.unique_stocks,
                    s.avg_quantity,
                    s.total_volume,
                    COALESCE(t.most_traded_stock, 'N/A') as most_traded_stock
                FROM stats s
                CROSS JOIN top_stock t
                """
                
                result = session.sql(trader_stats_query).to_pandas()
                
                if len(result) > 0:
                    row = result.iloc[0]
                    # Create trade summary for AI analysis
                    trade_summary = f"""
                    Trader: {selected_trader}
                    Total Trades: {row['TOTAL_TRADES']}
                    Unique Stocks: {row['UNIQUE_STOCKS']}
                    Average Quantity: {row['AVG_QUANTITY']:.0f}
                    Most Traded Stock: {row['MOST_TRADED_STOCK']}
                    Total Volume: {row['TOTAL_VOLUME']:,}
                    """
                else:
                    trade_summary = f"No trades found for trader: {selected_trader}"
                
                # AI_COMPLETE for insights
                insights_query = f"""
                SELECT AI_COMPLETE('mistral-7b', 
                    'Analyze this trader\\'s performance and provide 3 key insights about their trading patterns and risk profile: {trade_summary}'
                ) as trading_insights
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(insights_query, language="sql")
                    st.write("Using AI_COMPLETE to analyze trader performance data and generate intelligent insights about trading patterns, risk profile, and recommendations.")
                
                result = session.sql(insights_query).to_pandas()
                
                st.success("‚úÖ AI Analysis Complete!")
                
                # Format the AI insights better
                st.markdown("### üß† AI-Generated Trading Insights")
                
                insights_text = result['TRADING_INSIGHTS'].iloc[0]
                
                # Clean up the text and format it properly
                # Remove extra whitespace and newlines
                cleaned_text = insights_text.replace('\\n', '\n').strip()
                
                # Create an attractive container for the insights
                with st.container():
                    st.markdown("""
                    <div style="background-color: #f8f9fa; padding: 25px; border-radius: 12px; border-left: 5px solid #1f77b4; margin: 10px 0;">
                    """, unsafe_allow_html=True)
                    
                    # Split the text into sections and format each one
                    sections = cleaned_text.split('\n\n')
                    
                    for i, section in enumerate(sections):
                        section = section.strip()
                        if not section:
                            continue
                            
                        # Check if this is an introduction/header
                        if i == 0 and not any(section.startswith(marker) for marker in ['1.', '2.', '3.', '1)', '2)', '3)', '‚Ä¢', '-']):
                            st.markdown(f"**{section}**")
                            st.markdown("---")
                            continue
                        
                        # Process numbered insights
                        lines = section.split('\n')
                        for line in lines:
                            line = line.strip()
                            if not line:
                                continue
                                
                            # Handle numbered points (1., 2., 3.)
                            if any(line.startswith(f"{num}.") for num in ['1', '2', '3']):
                                # Extract the title and content
                                parts = line.split(':', 1)
                                if len(parts) == 2:
                                    title = parts[0].strip()
                                    content = parts[1].strip()
                                    
                                    # Create an insight card
                                    st.markdown(f"""
                                    <div style="background-color: white; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #28a745;">
                                        <h4 style="color: #28a745; margin-top: 0;">{title}</h4>
                                        <p style="margin-bottom: 0; line-height: 1.6;">{content}</p>
                                    </div>
                                    """, unsafe_allow_html=True)
                                else:
                                    # Fallback for different formatting
                                    st.markdown(f"""
                                    <div style="background-color: white; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #28a745;">
                                        <p style="margin: 0; line-height: 1.6;"><strong>{line}</strong></p>
                                    </div>
                                    """, unsafe_allow_html=True)
                            else:
                                # Handle continuation text or other content
                                if line:
                                    st.markdown(f"<p style='margin: 5px 0; line-height: 1.6; color: #555;'>{line}</p>", unsafe_allow_html=True)
                    
                    st.markdown("</div>", unsafe_allow_html=True)
                
                # Add trader summary for context
                st.markdown("---")
                st.markdown("### üìä Trader Performance Summary")
                
                # Get the stats from our earlier query
                trader_stats_result = session.sql(trader_stats_query).to_pandas()
                if len(trader_stats_result) > 0:
                    stats_row = trader_stats_result.iloc[0]
                    
                    # Create metrics columns for the summary
                    col1, col2, col3, col4 = st.columns(4)
                    
                    with col1:
                        st.metric(
                            label="Total Trades",
                            value=f"{stats_row['TOTAL_TRADES']:,}",
                            help="Total number of trades executed"
                        )
                    
                    with col2:
                        st.metric(
                            label="Unique Stocks",
                            value=f"{stats_row['UNIQUE_STOCKS']:,}",
                            help="Number of different stocks traded"
                        )
                    
                    with col3:
                        avg_qty = stats_row['AVG_QUANTITY']
                        if avg_qty is not None:
                            st.metric(
                                label="Avg Trade Size",
                                value=f"{avg_qty:,.0f}",
                                help="Average number of shares per trade"
                            )
                        else:
                            st.metric(label="Avg Trade Size", value="N/A")
                    
                    with col4:
                        total_vol = stats_row['TOTAL_VOLUME']
                        if total_vol is not None:
                            st.metric(
                                label="Total Volume",
                                value=f"{total_vol:,.0f}",
                                help="Total shares traded"
                            )
                        else:
                            st.metric(label="Total Volume", value="N/A")
                    
                    # Most traded stock info
                    most_traded = stats_row['MOST_TRADED_STOCK']
                    if most_traded and most_traded != 'N/A':
                        st.info(f"üéØ **Most Traded Stock:** {most_traded}")
                
            except Exception as e:
                st.error(f"‚ùå Error generating insights: {e}")
                st.error("Debug info: Check if AI_COMPLETE function is available and properly configured")
    
    # AI_CLASSIFY for trade categorization
    st.subheader("üè∑Ô∏è Trade Classification")
    
    if st.button("üìä Classify Recent Trades"):
        with st.spinner("üè∑Ô∏è Classifying trades..."):
            try:
                # Use smart sampling for AI classification
                sample_limit = min(sample_size, 50)  # Limit classification to reasonable number
                
                classify_query = f"""
                WITH sample_trades AS (
                    {get_sample_data_sql(sample_limit, date_filter)}
                ),
                trade_descriptions AS (
                    SELECT 
                        "DATE",
                        "SYMBOL",
                        "NUM_SHARES",
                        "TRADER",
                        "ACTION",
                        CONCAT('Stock: ', "SYMBOL", ', Shares: ', "NUM_SHARES", ', Action: ', "ACTION", ', Trader: ', "TRADER") as trade_description
                    FROM sample_trades
                )
                SELECT 
                    "DATE",
                    "SYMBOL",
                    "NUM_SHARES",
                    "TRADER",
                    "ACTION",
                    AI_CLASSIFY(
                        trade_description,
                        [
                            {{'label': 'high_volume', 'description': 'trades with significantly high share quantities indicating major market moves'}},
                            {{'label': 'medium_volume', 'description': 'trades with moderate share quantities representing typical trading activity'}},
                            {{'label': 'low_volume', 'description': 'trades with small share quantities indicating minor position adjustments'}},
                            {{'label': 'unusual_activity', 'description': 'trades with patterns that deviate from normal trading behavior'}},
                            {{'label': 'institutional_trade', 'description': 'trades that appear to be from institutional investors based on size and timing'}},
                            {{'label': 'day_trading', 'description': 'trades that appear to be short-term day trading activities'}}
                        ],
                        {{
                            'task_description': 'Classify trading transactions based on volume patterns, trading behavior, and market activity characteristics',
                            'output_mode': 'multi',
                            'examples': [
                                {{
                                    'input': 'Stock: AAPL, Shares: 50000, Action: BUY, Trader: INSTITUTIONAL_TRADER_1',
                                    'labels': ['high_volume', 'institutional_trade'],
                                    'explanation': 'Large share quantity of 50,000 indicates high volume trade likely from institutional investor'
                                }},
                                {{
                                    'input': 'Stock: TSLA, Shares: 100, Action: SELL, Trader: RETAIL_TRADER_2',
                                    'labels': ['low_volume'],
                                    'explanation': 'Small share quantity of 100 shares represents typical retail trading activity'
                                }}
                            ]
                        }}
                    ) as ai_classification
                FROM trade_descriptions
                ORDER BY "DATE" DESC
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(classify_query, language="sql")
                    st.write("Using enhanced AI_CLASSIFY with detailed label descriptions, task context, and examples to categorize trades across multiple dimensions: volume patterns (high/medium/low), trading behavior (institutional/day trading), and unusual activity detection. The 'multi' output mode allows multiple labels per trade.")
                
                classification_results = session.sql(classify_query).to_pandas()
                
                if len(classification_results) > 0:
                    st.success(f"‚úÖ Enhanced Classification Complete! Analyzed {len(classification_results)} trades with multi-label categorization")
                    
                    # Show summary of classifications
                    st.markdown("**üìä Classification Results Summary:**")
                    st.markdown("Each trade can receive multiple labels based on volume patterns, trading behavior, and market activity characteristics.")
                    
                    st.dataframe(classification_results, use_container_width=True)
                    
                    # Optional: Show a sample of the classification results in a more readable format
                    if len(classification_results) > 0:
                        st.markdown("**üîç Sample Classification Analysis:**")
                        sample_trade = classification_results.iloc[0]
                        st.write(f"**Trade Example:** {sample_trade['SYMBOL']} - {sample_trade['NUM_SHARES']:,} shares ({sample_trade['ACTION']})")
                        st.write(f"**AI Classification:** {sample_trade['AI_CLASSIFICATION']}")
                else:
                    st.warning("‚ö†Ô∏è No trades found to classify. Try adjusting your date filter or sample size.")
                
            except Exception as e:
                st.error(f"‚ùå Error classifying trades: {e}")
                st.error("Debug info: Check if AI_CLASSIFY function is available and sample data exists")

# =================== INTELLIGENT FILTERING ===================
elif analysis_type == "üîç Intelligent Filtering":
    st.header("üîç Intelligent Trade Filtering")
    
    st.markdown("Use natural language to filter your trading data! Includes both basic filtering and advanced JOIN operations where AI_FILTER is used directly in the ON clause to intelligently match news headlines with related trades.")
    
    filter_options = [
        "Show me high-volume trades",
        "Find potentially risky transactions", 
        "Show me trades that might indicate market volatility",
        "Find trades with unusual timing patterns",
        "Show me trades that suggest strong market confidence"
    ]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üéØ Quick Filters")
        selected_filter = st.selectbox("Choose a suggested filter:", [""] + filter_options)
        
        # Auto-populate the text input when a filter is selected
        if selected_filter:
            filter_query = selected_filter
        else:
            filter_query = ""
    
    with col2:
        st.subheader("‚öôÔ∏è Settings")
        custom_threshold = st.number_input("Quantity Threshold:", min_value=1, value=50)
    
    # Natural language filter input - use the selected filter as default
    st.subheader("üó£Ô∏è Filter Description")
    filter_query = st.text_input(
        "Describe what trades you want to see:",
        value=filter_query,  # Pre-populate with selected filter
        placeholder="e.g., 'Show me high-risk trades' or 'Find trades with unusual patterns'"
    )
    
    if filter_query and st.button("üîç Apply AI Filter", type="primary"):
        with st.spinner("ü§ñ Applying intelligent filter..."):
            try:
                # Use smart sampling for AI filtering
                filter_limit = min(sample_size, 100)  # Limit for AI_FILTER performance
                
                filter_sql = f"""
                WITH sample_trades AS (
                    {get_sample_data_sql(filter_limit, date_filter)}
                ),
                trade_descriptions AS (
                    SELECT 
                        "DATE",
                        "SYMBOL",
                        "NUM_SHARES",
                        "TRADER",
                        "ACTION",
                        CONCAT('Trade: Stock ', "SYMBOL", ', Shares: ', "NUM_SHARES", ', Trader: ', "TRADER", ', Action: ', "ACTION", ', Date: ', "DATE") as trade_description
                    FROM sample_trades
                )
                SELECT 
                    "DATE",
                    "SYMBOL",
                    "NUM_SHARES",
                    "TRADER",
                    "ACTION"
                FROM trade_descriptions
                WHERE AI_FILTER(PROMPT('{filter_query}: {{0}}', trade_description))
                ORDER BY "DATE" DESC
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(filter_sql, language="sql")
                    st.write(f"Using AI_FILTER with PROMPT to intelligently evaluate trade data against your criteria: '{filter_query}'. The AI will analyze each trade and determine if it matches your requirements.")
                
                filtered_results = session.sql(filter_sql).to_pandas()
                
                if len(filtered_results) > 0:
                    st.success(f"‚úÖ AI_FILTER found {len(filtered_results)} matching trades!")
                    
                    # Show summary stats
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Filtered Trades", len(filtered_results))
                    with col2:
                        st.metric("Avg Volume", f"{filtered_results['NUM_SHARES'].mean():,.0f}")
                    with col3:
                        st.metric("Unique Stocks", filtered_results['SYMBOL'].nunique())
                    
                    st.dataframe(filtered_results, use_container_width=True)
                else:
                    st.info("‚ÑπÔ∏è AI_FILTER found no trades matching your criteria. Try a different filter or broader terms.")
                    
            except Exception as e:
                st.error(f"‚ùå AI_FILTER error: {e}")
                st.warning("üîÑ Falling back to rule-based filtering...")
                
                # Fallback to rule-based filtering (keeping the existing fallback code)
                try:
                    sample_query = f"""
                    WITH sample_trades AS (
                        {get_sample_data_sql(filter_limit, date_filter)}
                    )
                    SELECT 
                        "DATE",
                        "SYMBOL",
                        "NUM_SHARES",
                        "TRADER",
                        "ACTION"
                    FROM sample_trades
                    ORDER BY "DATE" DESC
                    """
                    
                    sample_results = session.sql(sample_query).to_pandas()
                    
                    if len(sample_results) > 0:
                        # Apply rule-based filtering
                        filtered_df = sample_results.copy()
                        filter_applied = False
                        
                        if "high-volume" in filter_query.lower() or "high volume" in filter_query.lower():
                            threshold = sample_results['NUM_SHARES'].quantile(0.8)
                            filtered_df = filtered_df[filtered_df['NUM_SHARES'] >= threshold]
                            st.info(f"üìä Rule-based filter: high-volume trades (>= {threshold:.0f} shares)")
                            filter_applied = True
                            
                        elif "low-volume" in filter_query.lower() or "low volume" in filter_query.lower():
                            threshold = sample_results['NUM_SHARES'].quantile(0.2)
                            filtered_df = filtered_df[filtered_df['NUM_SHARES'] <= threshold]
                            st.info(f"üìä Rule-based filter: low-volume trades (<= {threshold:.0f} shares)")
                            filter_applied = True
                            
                        elif "risky" in filter_query.lower() or "risk" in filter_query.lower():
                            threshold = sample_results['NUM_SHARES'].quantile(0.9)
                            filtered_df = filtered_df[filtered_df['NUM_SHARES'] >= threshold]
                            st.info(f"‚ö†Ô∏è Rule-based filter: high-risk trades (>= {threshold:.0f} shares)")
                            filter_applied = True
                            
                        elif "volatility" in filter_query.lower() or "volatile" in filter_query.lower():
                            stock_counts = sample_results.groupby('SYMBOL').size()
                            volatile_stocks = stock_counts[stock_counts >= stock_counts.quantile(0.7)].index
                            filtered_df = filtered_df[filtered_df['SYMBOL'].isin(volatile_stocks)]
                            st.info(f"üìà Rule-based filter: trades in frequently traded stocks")
                            filter_applied = True
                            
                        elif "confidence" in filter_query.lower() or "strong" in filter_query.lower():
                            threshold = sample_results['NUM_SHARES'].quantile(0.75)
                            filtered_df = filtered_df[filtered_df['NUM_SHARES'] >= threshold]
                            st.info(f"üí™ Rule-based filter: high-confidence trades (>= {threshold:.0f} shares)")
                            filter_applied = True
                        
                        if not filter_applied:
                            filtered_df = filtered_df[filtered_df['NUM_SHARES'] >= custom_threshold]
                            st.info(f"üîß Rule-based filter: custom threshold (>= {custom_threshold} shares)")
                        
                        if len(filtered_df) > 0:
                            st.success(f"‚úÖ Fallback filtering found {len(filtered_df)} trades!")
                            
                            # Show summary stats for fallback
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Filtered Trades", len(filtered_df))
                            with col2:
                                st.metric("Avg Volume", f"{filtered_df['NUM_SHARES'].mean():,.0f}")
                            with col3:
                                st.metric("Unique Stocks", filtered_df['SYMBOL'].nunique())
                            
                            st.dataframe(filtered_df, use_container_width=True)
                        else:
                            st.warning("‚ö†Ô∏è No trades matched the fallback criteria either.")
                    
                except Exception as fallback_error:
                    st.error(f"‚ùå Fallback filtering also failed: {fallback_error}")
    
    # Advanced AI_FILTER with JOIN demonstration
    st.markdown("---")
    st.subheader("üîó Advanced AI_FILTER with JOIN")
    st.markdown("Demonstrate AI_FILTER used directly in JOIN clauses to intelligently match news headlines with related trades - following the pattern: `JOIN news JOIN trade ON AI_FILTER(PROMPT('...', news.headline, trade.symbol))`")
    
    col1, col2 = st.columns(2)
    with col1:
        join_filter_options = [
            "Find news headlines that might have influenced trades",
            "Match breaking news with related trading activity", 
            "Identify news events that correlate with stock movements",
            "Find news stories relevant to specific trading patterns"
        ]
        selected_join_filter = st.selectbox("Choose a join filter scenario:", [""] + join_filter_options)
    
    with col2:
        advanced_sample_size = st.selectbox("Advanced Filter Sample Size:", [20, 50, 100], index=1)
    
    if selected_join_filter and st.button("üîó Apply Advanced AI Filter with JOIN", type="primary"):
        with st.spinner("ü§ñ Applying advanced AI filter with joins..."):
            try:
                # Create enhanced filter query using AI_FILTER in JOIN
                join_filter_limit = min(advanced_sample_size, 100)
                
                advanced_filter_sql = f"""
                -- AI_FILTER JOIN Pattern: Match news headlines with relevant trades
                -- Following: SELECT * FROM news JOIN trade ON AI_FILTER(PROMPT('...', news.headline, trade.symbol))
                WITH sample_trades AS (
                    {get_sample_data_sql(join_filter_limit, date_filter)}
                )
                SELECT 
                    t."DATE" as trade_date,
                    t."SYMBOL",
                    t."NUM_SHARES", 
                    t."TRADER",
                    t."ACTION",
                    n."DATE" as news_date,
                    n.NEWS_HEADLINE
                FROM sample_trades t
                JOIN FINSERVAM_DEMO.AISQL_DEMO.MARKET_NEWS n
                ON AI_FILTER(
                    PROMPT(
                        '{selected_join_filter}: Does this news {{0}} relate to this trade {{1}}?',
                        n.NEWS_HEADLINE,
                        CONCAT('Stock: ', t."SYMBOL", ', Shares: ', t."NUM_SHARES", ', Action: ', t."ACTION", ', Trader: ', t."TRADER")
                    )
                )
                ORDER BY t."DATE" DESC, n."DATE" DESC
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(advanced_filter_sql, language="sql")
                    st.write(f"Using AI_FILTER directly in the ON clause to intelligently match news headlines with related trades. This follows the exact pattern: JOIN news JOIN trade ON AI_FILTER(PROMPT('...', news.headline, trade.symbol)). Scenario: '{selected_join_filter}'.")
                
                join_filtered_results = session.sql(advanced_filter_sql).to_pandas()
                
                if len(join_filtered_results) > 0:
                    st.success(f"‚úÖ Advanced AI_FILTER with JOIN found {len(join_filtered_results)} intelligent news-trade matches!")
                    
                    # Show enhanced summary stats
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("News-Trade Matches", len(join_filtered_results))
                    with col2:
                        st.metric("Unique Symbols", join_filtered_results['SYMBOL'].nunique())
                    with col3:
                        st.metric("Unique Traders", join_filtered_results['TRADER'].nunique())
                    with col4:
                        st.metric("News Headlines", join_filtered_results['NEWS_HEADLINE'].nunique())
                    
                    # Display results with enhanced information
                    st.markdown("**üì∞ Intelligent News-Trade Correlations:**")
                    st.markdown("These are news headlines that the AI determined are relevant to specific trades based on content analysis and market relevance.")
                    st.dataframe(join_filtered_results, use_container_width=True)
                    
                    # Show sample match explanation
                    if len(join_filtered_results) > 0:
                        st.markdown("**üí° Sample News-Trade Match Analysis:**")
                        sample_match = join_filtered_results.iloc[0]
                        st.write(f"**Trade:** {sample_match['SYMBOL']} - {sample_match['NUM_SHARES']:,} shares ({sample_match['ACTION']}) by {sample_match['TRADER']} on {sample_match['TRADE_DATE']}")
                        st.write(f"**Related News:** {sample_match['NEWS_HEADLINE']} (News Date: {sample_match['NEWS_DATE']})")
                        st.write(f"**AI Reasoning:** The AI determined this news headline is relevant to this trade based on content analysis and market correlation")
                        
                else:
                    st.info("‚ÑπÔ∏è Advanced AI_FILTER found no news-trade correlations. The AI couldn't find news headlines that relate to the selected trades for this scenario.")
                    
            except Exception as e:
                st.error(f"‚ùå Advanced AI_FILTER with JOIN error: {e}")
                st.error("Debug info: Check if AI_FILTER function supports JOIN operations and table access permissions")

# =================== MARKET SENTIMENT ===================
elif analysis_type == "üìà Market Sentiment":
    st.header("üìà Market Sentiment Analysis")
    
    st.markdown("Perform multi-dimensional sentiment analysis on financial news headlines across key aspects: market outlook, company performance, economic impact, investor confidence, and risk factors.")
    
    # AI_SENTIMENT and AI_SUMMARIZE_AGG for news analysis - stacked vertically
    st.subheader("üì∞ News Headlines Sentiment")
    if st.button("üé≠ Analyze News Sentiment"):
        with st.spinner("üé≠ Analyzing news sentiment..."):
            try:
                # Limit for sentiment analysis
                sentiment_limit = min(sample_size, 100)
                
                sentiment_query = f"""
                WITH recent_news AS (
                    SELECT 
                        "DATE",
                        NEWS_HEADLINE,
                        ROW_NUMBER() OVER (ORDER BY "DATE" DESC) as rn
                    FROM FINSERVAM_DEMO.AISQL_DEMO.MARKET_NEWS
                    WHERE NEWS_HEADLINE IS NOT NULL AND LENGTH(NEWS_HEADLINE) > 10
                )
                SELECT 
                    "DATE" as news_date,
                    NEWS_HEADLINE,
                    AI_SENTIMENT(
                        NEWS_HEADLINE,
                        ['market_outlook', 'company_performance', 'economic_impact', 'investor_confidence', 'risk_factors']
                    ) as sentiment_analysis
                FROM recent_news
                WHERE rn <= {sentiment_limit}
                ORDER BY "DATE" DESC
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(sentiment_query, language="sql")
                    st.write("Using AI_SENTIMENT with column reference and financial aspects array ['market_outlook', 'company_performance', 'economic_impact', 'investor_confidence', 'risk_factors'] to perform multi-dimensional sentiment analysis on news headlines, providing detailed insights across key financial dimensions.")
                
                sentiment_results = session.sql(sentiment_query).to_pandas()
                
                # Now process the results if we have any
                if len(sentiment_results) > 0:
                    st.success(f"‚úÖ Multi-Dimensional News Sentiment Analysis Complete! Analyzed {len(sentiment_results)} headlines across 5 financial aspects")
                    
                    st.markdown("**üìä Sentiment Analysis Results:**")
                    st.markdown("Each headline is analyzed across multiple financial dimensions: market outlook, company performance, economic impact, investor confidence, and risk factors.")
                    
                    st.dataframe(sentiment_results, use_container_width=True)
                    
                    # Show detailed sample analysis
                    if len(sentiment_results) > 0:
                        st.markdown("**üí° Sample Multi-Dimensional Sentiment Analysis:**")
                        sample_news = sentiment_results.iloc[0]
                        
                        st.write(f"**üì∞ Headline:** {sample_news['NEWS_HEADLINE']}")
                        st.write(f"**üìÖ Date:** {sample_news['NEWS_DATE']}")
                        st.write(f"**üéØ Multi-Aspect Sentiment Analysis:**")
                        
                        # Display the sentiment analysis result
                        sentiment_analysis = sample_news['SENTIMENT_ANALYSIS']
                        if isinstance(sentiment_analysis, str):
                            # If it's a JSON string, try to format it nicely
                            try:
                                if sentiment_analysis.startswith('{') or sentiment_analysis.startswith('['):
                                    formatted_sentiment = json.loads(sentiment_analysis)
                                    st.json(formatted_sentiment)
                                else:
                                    st.write(sentiment_analysis)
                            except:
                                st.write(sentiment_analysis)
                        else:
                            st.write(sentiment_analysis)
                        
                        st.markdown("**üìà Analysis Dimensions:**")
                        st.markdown("""
                        - **Market Outlook**: Overall market direction sentiment
                        - **Company Performance**: Individual company assessment  
                        - **Economic Impact**: Broader economic implications
                        - **Investor Confidence**: Market participant sentiment
                        - **Risk Factors**: Potential risks and concerns
                        """)
                else:
                    st.warning("‚ö†Ô∏è No sufficient news data for sentiment analysis. Check if the MARKET_NEWS table has data.")
                
            except Exception as e:
                st.error(f"‚ùå Error analyzing news sentiment: {e}")
                st.error("Debug info: Check if AI_SENTIMENT function is available and MARKET_NEWS table exists")
    
    # Stacked vertically - News Summary Insights section
    st.subheader("üì∞ News Summary & Market Themes")
    if st.button("üìã Generate News Summary"):
        with st.spinner("üìã Summarizing market news..."):
            try:
                # Use sample size for news analysis
                news_sample = min(sample_size * 2, 500)  # Larger sample for comprehensive summary
                
                summarize_query = f"""
                WITH recent_news AS (
                    SELECT 
                        NEWS_HEADLINE,
                        "DATE",
                        ROW_NUMBER() OVER (ORDER BY "DATE" DESC) as rn
                    FROM FINSERVAM_DEMO.AISQL_DEMO.MARKET_NEWS
                    WHERE NEWS_HEADLINE IS NOT NULL AND LENGTH(NEWS_HEADLINE) > 10
                )
                SELECT 
                    COUNT(*) as headlines_analyzed,
                    MIN("DATE") as earliest_news,
                    MAX("DATE") as latest_news,
                    AI_SUMMARIZE_AGG(NEWS_HEADLINE) as market_summary
                FROM recent_news
                WHERE rn <= {news_sample}
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(summarize_query, language="sql")
                    st.write("Using AI_SUMMARIZE_AGG to analyze and summarize news headlines, extracting key market themes, trends, sentiment patterns, and emerging stories that are driving financial markets.")
                
                result = session.sql(summarize_query).to_pandas()
                
                if len(result) > 0 and result['MARKET_SUMMARY'].iloc[0]:
                    summary_data = result.iloc[0]
                    
                    st.success(f"‚úÖ News Summary Complete! Analyzed {summary_data['HEADLINES_ANALYZED']} headlines")
                    
                    # Show summary metrics
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("üì∞ Headlines Analyzed", f"{summary_data['HEADLINES_ANALYZED']:,}")
                    with col2:
                        st.metric("üìÖ Date Range", f"{summary_data['EARLIEST_NEWS']} to")
                        st.write(f"                     {summary_data['LATEST_NEWS']}")
                    with col3:
                        st.metric("üéØ Analysis Scope", "Market Themes")
                    
                    st.markdown("### üìä AI-Generated Market Summary:")
                    
                    # Display the summary with better formatting
                    market_summary = summary_data['MARKET_SUMMARY']
                    st.markdown("**üîç Key Market Themes & Insights:**")
                    
                    # Try to format as paragraphs if it's a long summary
                    if isinstance(market_summary, str) and len(market_summary) > 200:
                        # Split into paragraphs for better readability
                        paragraphs = market_summary.replace('. ', '.\n\n').split('\n\n')
                        for i, paragraph in enumerate(paragraphs):
                            if paragraph.strip():
                                st.write(f"**{i+1}.** {paragraph.strip()}")
                    else:
                        st.write(market_summary)
                    
                    st.markdown("---")
                    st.markdown("**üí° About this Analysis:**")
                    st.markdown(f"""
                    This summary was generated by analyzing {summary_data['HEADLINES_ANALYZED']} recent financial news headlines 
                    using AI_SUMMARIZE_AGG. The AI identifies recurring themes, sentiment patterns, sector trends, 
                    and emerging stories that are shaping market sentiment and investor behavior.
                    """)
                    
                else:
                    st.warning("‚ö†Ô∏è No sufficient news data for summary analysis. Check if the MARKET_NEWS table has data.")
                
            except Exception as e:
                st.error(f"‚ùå Error generating news summary: {e}")
                st.error("Debug info: Check if AI_SUMMARIZE_AGG function is available and MARKET_NEWS table exists")

# =================== DOCUMENT ANALYSIS ===================
elif analysis_type == "üìÑ Document Analysis":
    st.header("üìÑ Financial Document Analysis")
    
    st.markdown("Parse and extract insights from financial documents using AI. Analyze annual reports, SEC filings, research reports, and earnings statements with advanced document processing capabilities.")
    
    # AI_PARSE_DOCUMENT section
    st.subheader("üìã Document Parsing & Layout Analysis")
    st.markdown("Use AI_PARSE_DOCUMENT to parse financial documents with layout awareness and structured content extraction.")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Document stage/path selection
        st.markdown("**üìÅ Document Source:**")
        doc_stage_options = [
            "@FINSERVAM_DEMO.AISQL_DEMO.FINANCIAL_DOCS" 
            
        ]
        selected_stage = st.selectbox("Select document stage:", doc_stage_options, help="Choose the Snowflake stage containing financial documents")
    
    with col2:
        # Document type and parsing options
        st.markdown("**‚öôÔ∏è Parsing Options:**")
        parse_mode = st.selectbox("Parse Mode:", ["LAYOUT", "OCR"], index=0)
        page_split = st.checkbox("Split by pages", value=True)
    
    # Sample documents
    st.markdown("**üìÑ Sample Financial Documents:**")
    doc_examples = [
       "FY23_Q4_Consolidated_Financial_Statements.pdf"
        # "apple-annual-report-2023.pdf",
        # "tesla-10k-filing.pdf", 
        # "microsoft-earnings-transcript.pdf",
        # "jpmorgan-research-report.pdf",
        # "fed-monetary-policy-statement.pdf"
    ]
    selected_document = st.selectbox("Choose a sample document:", [""] + doc_examples)
    
    if selected_document and st.button("üìñ Parse Financial Document"):
        with st.spinner("üìñ Parsing document with AI..."):
            try:
                parse_options = {
                    'mode': parse_mode,
                    'page_split': page_split
                }
                    
                parse_query = f"""
                SELECT 
                    '{selected_document}' as document_name,
                    AI_PARSE_DOCUMENT(
                        TO_FILE('{selected_stage}', '{selected_document}'),
                        {parse_options}
                    ) as parsed_content
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(parse_query, language="sql")
                    st.write(f"Using AI_PARSE_DOCUMENT to parse '{selected_document}' with {parse_mode.lower()} mode, extracting structured content with layout awareness and page splitting.")
                
                result = session.sql(parse_query).to_pandas()
                
                if len(result) > 0:
                    st.success(f"‚úÖ Document Parsing Complete! Analyzed: {selected_document}")
                    
                    # Display parsed content
                    parsed_content = result['PARSED_CONTENT'].iloc[0]
                    
                    st.markdown("### üìä Parsed Document Content:")
                    if isinstance(parsed_content, str) and len(parsed_content) > 1000:
                        # Show first part with option to expand
                        st.text_area("Document Content (Preview)", parsed_content[:1000] + "...", height=200, disabled=True)
                        
                        with st.expander("üìñ View Complete Document Content"):
                            st.text(parsed_content)
                    else:
                        st.text_area("Document Content", str(parsed_content), height=300, disabled=True)
                    
                    st.markdown("**üí° Document Analysis Insights:**")
                    st.markdown(f"""
                    - **Document**: {selected_document}
                    - **Parse Mode**: {parse_mode} (Layout-aware content extraction)
                    - **Page Splitting**: {'Enabled' if page_split else 'Disabled'}
                    - **Content Length**: {len(str(parsed_content)):,} characters
                    - **Analysis Type**: Financial document structure and content parsing
                    """)
                else:
                    st.warning("‚ö†Ô∏è No content could be parsed from the document.")
                    
            except Exception as e:
                st.error(f"‚ùå Error parsing document: {e}")
                st.error("Debug info: Check if AI_PARSE_DOCUMENT function is available and document stage exists")
    
    st.markdown("---")
    
    # AI_EXTRACT section
    st.subheader("üéØ Targeted Information Extraction")
    st.markdown("Use AI_EXTRACT to extract specific financial metrics and insights from documents using natural language queries.")
    
    # Financial extraction templates
    extraction_templates = {
        "üìä Financial Metrics": [
            ['total_net_sales', 'What is the total net sales for the current period?'],
            # ['cost_of_revenue', 'What is the cost of goods sold or cost of revenue?'],
            # ['gross_profit', 'What is the gross profit for the period?'],
            ['operating_income', 'What is the operating income for the current period'],
            # ['net_income', 'What is the net income or net loss for the period?'],
            ['basic_eps', 'What is the basic earnings per share for the current period?'],
            ['diluted_eps', 'What is the diluted earnings per share for the current period?'],
            # ['weighted_avg_shares', 'What are the weighted average shares outstanding?']
        ],
        "üìà Performance Indicators": [
            ['growth_rate', 'What is the revenue growth rate compared to previous year?'],
            ['profit_margin', 'What is the profit margin percentage?'],
            ['debt_ratio', 'What is the debt-to-equity ratio?'], 
            ['market_share', 'What is mentioned about market share or competitive position?']
        ],
        "‚ö†Ô∏è Risk Factors": [
            ['key_risks', 'What are the main risk factors mentioned?'],
            ['regulatory_risks', 'Are there any regulatory or compliance risks?'],
            ['market_risks', 'What market or economic risks are identified?'],
            ['operational_risks', 'Are there operational or business risks mentioned?']
        ],
        "üéØ Strategic Insights": [
            ['business_strategy', 'What is the company business strategy or focus?'],
            ['future_outlook', 'What is the outlook or guidance for next year?'],
            ['investments', 'What major investments or initiatives are planned?'],
            ['competitive_position', 'How does the company position itself versus competitors?']
        ]
    }
    
    col1, col2 = st.columns(2)
    
    with col1:
        extraction_category = st.selectbox("Extraction Category:", list(extraction_templates.keys()))
        document_for_extract = st.selectbox("Document to analyze:", [""] + doc_examples, key="extract_doc")
    
    with col2:
        # Show the questions that will be asked for the selected category
        if extraction_category:
            st.markdown(f"**Questions for {extraction_category}:**")
            for field, question in extraction_templates[extraction_category]:
                st.write(f"‚Ä¢ {question}")
    
    if document_for_extract and st.button("üîç Extract Financial Information"):
        with st.spinner("üîç Extracting information with AI..."):
            try:
                # Build the extraction query
                response_format = extraction_templates[extraction_category]
                
                extract_query = f"""
                SELECT 
                    '{document_for_extract}' as document_name,
                    AI_EXTRACT(
                        file => TO_FILE('{selected_stage}', '{document_for_extract}'),
                        responseFormat => {response_format}
                    ) as extracted_data
                """
                
                # Show collapsible SQL query  
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(extract_query, language="sql")
                    st.write(f"Using AI_EXTRACT to extract {extraction_category.lower()} from '{document_for_extract}' using structured natural language queries.")
                
                result = session.sql(extract_query).to_pandas()
                
                if len(result) > 0:
                    st.success(f"‚úÖ Information Extraction Complete! Analyzed: {document_for_extract}")
                    
                    # Display extracted information
                    extracted_data = result['EXTRACTED_DATA'].iloc[0]
                    
                    st.markdown(f"### üéØ Extracted {extraction_category}:")
                    
                    # Try to parse as JSON for better display
                    if isinstance(extracted_data, str):
                        try:
                            import json
                            if extracted_data.startswith('{') or extracted_data.startswith('['):
                                formatted_data = json.loads(extracted_data)
                                
                                # Display as metrics/cards
                                if isinstance(formatted_data, dict):
                                    cols = st.columns(min(len(formatted_data), 3))
                                    for i, (key, value) in enumerate(formatted_data.items()):
                                        with cols[i % 3]:
                                            st.metric(key.replace('_', ' ').title(), str(value)[:100] + "..." if len(str(value)) > 100 else str(value))
                                
                                # Also show raw JSON
                                with st.expander("üìã View Raw Extracted Data"):
                                    st.json(formatted_data)
                            else:
                                st.write(extracted_data)
                        except:
                            st.write(extracted_data)
                    else:
                        st.write(str(extracted_data))
                    
                    st.markdown("**üí° Extraction Summary:**")
                    st.markdown(f"""
                    - **Document**: {document_for_extract}
                    - **Category**: {extraction_category}  
                    - **Questions Asked**: {len(response_format)} specific queries
                    - **Extraction Method**: Natural language to structured data
                    - **Use Case**: Financial document intelligence and automated reporting
                    """)
                else:
                    st.warning("‚ö†Ô∏è No information could be extracted from the document.")
                    
            except Exception as e:
                st.error(f"‚ùå Error extracting information: {e}")
                st.error("Debug info: Check if AI_EXTRACT function is available and document stage exists")

# =================== NATURAL LANGUAGE QUERIES ===================
elif analysis_type == "üí¨ Natural Language Queries":
    st.header("üí¨ Natural Language Trading Queries")
    
    st.markdown("Ask questions about your trading data in plain English!")
    
    # Predefined query examples
    st.subheader("üéØ Quick Questions")
    
    query_examples = [
        "What are the riskiest trades in my portfolio?",
        "Which stocks show the most volatile trading patterns?", 
        "What trading strategies would you recommend based on recent activity?",
        "Are there any unusual trading patterns I should be concerned about?",
        "What insights can you provide about market momentum?"
    ]
    
    selected_query = st.selectbox("Choose a question or type your own:", ["Custom Query"] + query_examples)
    
    if selected_query != "Custom Query":
        user_query = selected_query
    else:
        user_query = st.text_input("üí≠ Ask your question:", placeholder="e.g., What patterns do you see in recent trading activity?")
    
    if user_query and st.button("ü§ñ Get AI Answer"):
        with st.spinner("ü§ñ Analyzing your question..."):
            try:
                # Use sampled data for natural language queries
                context_sample = min(sample_size * 3, 5000)  # Reasonable sample for context
                
                complete_query = f"""
                WITH sample_data AS (
                    {get_sample_data_sql(context_sample, date_filter)}
                ),
                trading_context AS (
                    SELECT 
                        COUNT(*) as sample_trades,
                        COUNT(DISTINCT "SYMBOL") as unique_stocks,
                        SUM("NUM_SHARES") as total_volume,
                        COUNT(DISTINCT "TRADER") as active_traders,
                        MAX("NUM_SHARES") as highest_volume_trade,
                        AVG("NUM_SHARES") as avg_trade_size
                    FROM sample_data
                ),
                top_stocks AS (
                    SELECT LISTAGG("SYMBOL", ', ') WITHIN GROUP (ORDER BY trade_count DESC) as top_5_stocks
                    FROM (
                        SELECT "SYMBOL", COUNT(*) as trade_count
                        FROM sample_data
                        GROUP BY "SYMBOL"
                        ORDER BY trade_count DESC
                        LIMIT 5
                    )
                ),
                context_summary AS (
                    SELECT CONCAT(
                        'Recent Trading Analysis (', '{date_filter}', '): Sample Trades: ', tc.sample_trades,
                        ', Unique Stocks: ', tc.unique_stocks,
                        ', Total Volume: ', tc.total_volume, ' shares',
                        ', Active Traders: ', tc.active_traders,
                        ', Top 5 Most Traded Stocks: ', COALESCE(ts.top_5_stocks, 'N/A'),
                        ', Highest Volume Trade: ', tc.highest_volume_trade, ' shares',
                        ', Average Trade Size: ', ROUND(tc.avg_trade_size, 0), ' shares'
                    ) as context_data
                    FROM trading_context tc
                    CROSS JOIN top_stocks ts
                )
                SELECT AI_COMPLETE('mistral-7b',
                    CONCAT('Based on this recent financial trading data sample, please answer: {user_query}. Context: ', 
                           context_data, '. Note: This analysis is based on a recent sample, not the full dataset. Please provide actionable insights.')
                ) as ai_response
                FROM context_summary
                """
                
                # Show collapsible SQL query
                with st.expander("üîç View SQL Query", expanded=False):
                    st.code(complete_query, language="sql")
                    st.write(f"Using AI_COMPLETE to analyze trading data context and provide intelligent answers to your question: '{user_query}'. The AI will examine trading patterns, volumes, and trends to give actionable insights.")
                
                result = session.sql(complete_query).to_pandas()
                
                if len(result) > 0 and result['AI_RESPONSE'].iloc[0]:
                    st.success("‚úÖ AI Analysis Complete!")
                    
                    # Display the response in a beautifully formatted container
                    st.markdown("### ü§ñ AI Response")
                    
                    response = result['AI_RESPONSE'].iloc[0]
                    
                    # Create an attractive container for the AI response
                    with st.container():
                        st.markdown("""
                        <div style="background-color: #e8f4fd; padding: 20px; border-radius: 10px; border-left: 5px solid #0066cc;">
                        """, unsafe_allow_html=True)
                        
                        # Format the response with better structure
                        if '\n' in response:
                            # Split into paragraphs for better readability
                            paragraphs = [p.strip() for p in response.split('\n') if p.strip()]
                            for paragraph in paragraphs:
                                if paragraph:
                                    st.markdown(f"üí° {paragraph}")
                                    st.markdown("")  # Add spacing
                        else:
                            st.markdown(f"üí° **{response}**")
                        
                        st.markdown("</div>", unsafe_allow_html=True)
                    
                    # Add follow-up suggestions with better formatting
                    st.markdown("---")
                    st.markdown("### üéØ Recommended Follow-up Actions")
                    
                    follow_up_query = f"""
                    SELECT AI_COMPLETE('mistral-7b',
                        'Based on the previous analysis, suggest 3 specific follow-up actions or analyses that would be valuable for this trading portfolio.'
                    ) as follow_up_suggestions
                    """
                    
                    # Show follow-up query info (simpler since it's a quick follow-up)
                    st.markdown("**üìã Follow-up AI_COMPLETE Query:**")
                    st.code(follow_up_query, language="sql")
                    
                    follow_up_result = session.sql(follow_up_query).to_pandas()
                    if len(follow_up_result) > 0:
                        suggestions = follow_up_result['FOLLOW_UP_SUGGESTIONS'].iloc[0]
                        
                        # Format follow-up suggestions in a nice container
                        with st.container():
                            st.markdown("""
                            <div style="background-color: #f8f9fa; padding: 15px; border-radius: 8px; border-left: 4px solid #28a745;">
                            """, unsafe_allow_html=True)
                            
                            if '\n' in suggestions:
                                lines = [line.strip() for line in suggestions.split('\n') if line.strip()]
                                for line in lines:
                                    if line:
                                        if any(line.startswith(marker) for marker in ['1.', '2.', '3.', '‚Ä¢', '-']):
                                            st.markdown(f"‚úÖ **{line}**")
                                        else:
                                            st.markdown(f"‚úÖ {line}")
                            else:
                                st.markdown(f"‚úÖ **{suggestions}**")
                            
                            st.markdown("</div>", unsafe_allow_html=True)
                
            except Exception as e:
                st.error(f"‚ùå Error processing query: {e}")
                st.error("Debug info: Check if AI_COMPLETE function is available and sample data exists")

